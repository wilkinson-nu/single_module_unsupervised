{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "writer = SummaryWriter(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "import numpy as np\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class SingleModuleImage2D_augpair(Dataset):\n",
    "\n",
    "    def __init__(self, infilename, transform=None):\n",
    "        self._data = joblib.load(infilename)\n",
    "        self._length = len(self._data)\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        ## Convert the raw data to a dense pytorch tensor...\n",
    "        raw_data = torch.Tensor(self._data[idx].toarray())\n",
    "        \n",
    "        ## Apply transforms to augment the data\n",
    "        if not self._transform:\n",
    "            img1 = raw_data\n",
    "            img2 = raw_data\n",
    "        else:\n",
    "            img1 = self._transform(raw_data)\n",
    "            img2 = self._transform(raw_data)\n",
    "        \n",
    "        return img1, img2\n",
    "\n",
    "def collate_pair(batch):\n",
    "    img1_batch = torch.stack([item[0] for item in batch])\n",
    "    img2_batch = torch.stack([item[1] for item in batch])\n",
    "    return img1_batch, img2_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.v2.functional as F\n",
    "import random\n",
    "\n",
    "## Need to define a RandomRotation function that works for Tensors\n",
    "class RandomTensorRotation:\n",
    "    def __init__(self, min_angle, max_angle):\n",
    "        self.min_angle = min_angle\n",
    "        self.max_angle = max_angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        angle = torch.FloatTensor(1).uniform_(self.min_angle, self.max_angle).item()\n",
    "        return F.rotate(img.unsqueeze(0), angle).squeeze()\n",
    "\n",
    "## A function to randomly remove some number of blocks of size\n",
    "class RandomBlockZero:\n",
    "    def __init__(self, max_blocks=5, block_size=4):\n",
    "        self.max_blocks = max_blocks\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Randomly zero out blocks of 4x4 pixels\n",
    "        num_blocks_removed = random.randint(0, self.max_blocks)\n",
    "        for _ in range(num_blocks_removed):\n",
    "            this_size = self.block_size\n",
    "            block_x = random.randint(0, img.size(1) // this_size - 1) * this_size\n",
    "            block_y = random.randint(0, img.size(0) // this_size - 1) * this_size\n",
    "            img[block_y:block_y+4, block_x:block_x+4] = 0\n",
    "        return img    \n",
    "\n",
    "## A function to randomly shift the image by some number of pixels and crop it\n",
    "class RandomShiftTensor:\n",
    "    def __init__(self, max_shift=10):\n",
    "        self.max_shift = max_shift\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \n",
    "        height, width = img.shape\n",
    "\n",
    "        shift_x = random.randint(-self.max_shift, self.max_shift)\n",
    "        shift_y = random.randint(-self.max_shift, self.max_shift)\n",
    "\n",
    "        new_img = torch.zeros_like(img)\n",
    "\n",
    "        src_x1 = max(0, -shift_x)\n",
    "        src_y1 = max(0, -shift_y)\n",
    "        src_x2 = min(width, width - shift_x)\n",
    "        src_y2 = min(height, height - shift_y)\n",
    "\n",
    "        tgt_x1 = max(0, shift_x)\n",
    "        tgt_y1 = max(0, shift_y)\n",
    "        tgt_x2 = tgt_x1 + (src_x2 - src_x1)\n",
    "        tgt_y2 = tgt_y1 + (src_y2 - src_y1)\n",
    "\n",
    "        new_img[tgt_y1:tgt_y2, tgt_x1:tgt_x2] = img[src_y1:src_y2, src_x1:src_x2]\n",
    "\n",
    "        return new_img\n",
    "\n",
    "    \n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    RandomBlockZero(),\n",
    "    RandomTensorRotation(-10, 10),\n",
    "    RandomShiftTensor()\n",
    "])\n",
    "\n",
    "## Get a concrete dataset and data loader\n",
    "# inFile = \"/global/cfs/cdirs/dune/users/cwilk/single_module_images/sparse_joblib_fixdupes_pluscuts_noneg_transform/training_images_200k.joblib\"\n",
    "inFile = \"/global/cfs/cdirs/dune/users/cwilk/single_module_images/sparse_joblib_fixdupes_pluscuts_noneg_transform/packet_2022_02_11_11_39_26_CET_0cd913fb_20220211_113926.data.module1_flow_images.joblib\"\n",
    "start = time.process_time() \n",
    "train_dataset = SingleModuleImage2D_augpair(inFile, transform=aug_transform)\n",
    "print(\"Time taken to load\", train_dataset.__len__(),\"images:\", time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Randomly chosen batching\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           collate_fn=collate_pair,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4,\n",
    "                                           drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.process_time()\n",
    "minVal = 0\n",
    "maxVal = 0\n",
    "for img1_batch, img2_batch in train_loader:\n",
    "    if torch.max(img1_batch) > maxVal:\n",
    "        maxVal = torch.max(img1_batch)\n",
    "    if torch.min(img1_batch) < minVal:\n",
    "        minVal = torch.min(img1_batch)\n",
    "    if torch.max(img2_batch) > maxVal:\n",
    "        maxVal = torch.max(img2_batch)\n",
    "    if torch.min(img2_batch) < minVal:\n",
    "        minVal = torch.min(img2_batch)\n",
    "        \n",
    "print(\"Time taken to loop:\", time.process_time() - start)\n",
    "print(\"Found a minimum value of:\", minVal)\n",
    "print(\"Found a maximum value of:\", maxVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "# Access a specific instance\n",
    "img1, img2 = train_dataset[11]\n",
    "print(img1.size(), img2.size())\n",
    "\n",
    "# Visualize the image\n",
    "gr = plt.imshow(img1, origin='lower')\n",
    "plt.colorbar(gr)\n",
    "plt.show()\n",
    "gr = plt.imshow(img2, origin='lower')\n",
    "plt.colorbar(gr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n=10):  \n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    ## Loop over figures\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3,n,i+1)\n",
    "        ## This is not working the way I expect when shuffle is not on...\n",
    "        ## It always gives the first image...\n",
    "        img = next(iter(train_loader))\n",
    "        with torch.no_grad():\n",
    "            img = img.to(device)\n",
    "            # temp=encoder(img)\n",
    "            rec_img  = decoder(encoder(img))\n",
    "        this_input  = img[0].cpu().numpy().squeeze()\n",
    "        this_output = rec_img[0].cpu().numpy().squeeze()\n",
    "        \n",
    "        ## Input row\n",
    "        plt.imshow(this_input, cmap='viridis', origin='lower')            \n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "        if i == n//2: ax.set_title('Original images')\n",
    "        \n",
    "        ## Reconstructed row\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(this_output, cmap='viridis', origin='lower')  \n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "        if i == n//2: ax.set_title('Reconstructed images')\n",
    "        \n",
    "        ## In - rec row\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(this_input-this_output, cmap='viridis', origin='lower')  \n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "        if i == n//2: ax.set_title('Input - reco images')\n",
    "        \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_distribution_from_dataloader(data_loader, encoder, decoder):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # Initialize empty lists to store histogram counts\n",
    "    num_bins=50\n",
    "    input_hist = np.zeros(num_bins, dtype=int)\n",
    "    output_hist = np.zeros(num_bins, dtype=int)\n",
    "\n",
    "    # Create logarithmically spaced bins\n",
    "    # bins = np.logspace(0, np.log10(1000), num=num_bins+1)\n",
    "    bins = np.linspace(0.1, 3.1, num=num_bins+1)\n",
    "    with torch.no_grad():\n",
    "        for image_batch in data_loader:\n",
    "\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_batch = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_batch = decoder(encoded_batch)\n",
    "            \n",
    "            # Flatten input and output tensors to 1D arrays\n",
    "            # Update input histogram\n",
    "            input_hist += np.histogram(image_batch.cpu().numpy(), bins=bins)[0]\n",
    "\n",
    "            # Update output histogram\n",
    "            output_hist += np.histogram(decoded_batch.cpu().numpy(), bins=bins)[0]\n",
    "\n",
    "    # Plot distribution of input and output values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(bins[:-1], input_hist, color='blue', label='Input')\n",
    "    plt.plot(bins[:-1], output_hist, color='orange', label='Output')\n",
    "    plt.title('Distribution of Input and Output Values')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    # plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools",
   "language": "python",
   "name": "ml_tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
