{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import importlib\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.v2.functional as F\n",
    "from torch import nn\n",
    "\n",
    "## Jupyter magic\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "import numpy as np\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Includes from my libraries for this project                                                                                                                                           \n",
    "from ME_dataset_libs import make_dense, make_dense_from_tensor, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FSD_training_analysis import get_models_from_checkpoint\n",
    "\n",
    "## Load in the pre-calculated model weights\n",
    "file_dir = \"/pscratch/sd/c/cwilk\"\n",
    "\n",
    "## This is interesting, but limited so the best performance really is for ~N=20-30. The best silhouette is ~0.25\n",
    "# chk_file = \"state_lat64_hid128_clust25_nchan64_5E-6_1024_PROJ0.5one_CLUST0.5one_ent1E-1_soft1.0_arch24x8silu_poolmax_flat1_grow1_kern7_sep1_onecycle50_bigaugbilinfix0.5_DROP0_WEIGHT_DECAY0.05_10M_DATA1_FSDCCFIX.pth\"\n",
    "# chk_file=\"state_lat32_hid256_clust25_nchan48_1E-5_1024_PROJ0.5_CLUST0.5two_ent1E-1_soft1.0_arch12x4_poolmax_flat1_grow1_kern7_sep1_onecycle50_bigaugbilinfix_1M_DATA1_FSDCCFIX.pth\"\n",
    "\n",
    "## Try one with 24x8\n",
    "# chk_file=\"state_lat64_hid256_clust50_nchan64_5E-6_1024_PROJ0.5_CLUST0.5two_ent1E-1_soft1.0_arch24x8_poolmax_flat1_grow1_kern7_sep1_onecycle50_bigaugbilinfix0.5_5M_DATA1_FSDCCFIX.pth\"\n",
    "chk_file=\"state_lat128_hid256_clust30_nchan64_5E-6_1024_PROJ0.5two_CLUST0.5two_ent1E-1_soft1.0_archd4silu_poolmax_flat0_grow1_kern7_sep0_onecycle50_newbaseaug0.5_DROP0_WEIGHT_DECAY0_5M_DATA1_FSDCCFIX.pth\"\n",
    "encoder, heads, args = get_models_from_checkpoint(file_dir+\"/\"+chk_file)\n",
    "encoder.eval()\n",
    "for h in heads.values(): h.eval()\n",
    "\n",
    "encoder.to(device)\n",
    "for h in heads.values(): h.to(device)\n",
    "\n",
    "print(\"Loaded:\", chk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup the dataloader\n",
    "from FSD_training_analysis import get_dataset\n",
    "import time\n",
    "\n",
    "data_dir = \"/pscratch/sd/c/cwilk/FSD/DATA\"\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/FSD/SIMULATIONv2\"\n",
    "max_data_events=100000\n",
    "max_sim_events=100000\n",
    "\n",
    "start = time.time() \n",
    "sim_dataset, sim_loader = get_dataset(sim_dir, max_sim_events, return_metadata=True)\n",
    "data_dataset, data_loader = get_dataset(data_dir, max_data_events, return_metadata=True)\n",
    "print(\"Time taken to load\", data_dataset.__len__(),\"data and\", sim_dataset.__len__(), \"images:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import FSD_training_analysis\n",
    "importlib.reload(FSD_training_analysis)\n",
    "from FSD_training_analysis import image_loop, reorder_clusters\n",
    "import time\n",
    "start = time.time()\n",
    "## Get the processed vectors of interest from the datasets                                                                                                                                                     \n",
    "data_processed = image_loop(encoder, heads, data_loader, False)\n",
    "sim_processed = image_loop(encoder, heads, sim_loader, False)\n",
    "print(\"Time to process events:\", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "## Do some magic to re-order the clusters for presentation purposes                                                                                                                                            \n",
    "reorder_clusters(data_processed, sim_processed)\n",
    "print(\"Time to reorder events:\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ME_analysis_libs\n",
    "importlib.reload(ME_analysis_libs)\n",
    "from ME_analysis_libs import plot_metric_data_vs_sim\n",
    "\n",
    "plot_metric_data_vs_sim(data_processed['clust_index'],\n",
    "                        sim_processed['clust_index'], \n",
    "                        sim_processed['labels'],\n",
    "                        xtitle=\"Max. cluster index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play with some GMM options\n",
    "\n",
    "def calc_saliency(orig, encoder, clust_head, cluster_index, device=device):\n",
    "\n",
    "    # Prepare features with gradient enabled\n",
    "    feats  = orig.F.clone().detach().to(device)\n",
    "    feats.requires_grad_(True)\n",
    "\n",
    "    coords = orig.C.to(device)\n",
    "\n",
    "    st = ME.SparseTensor(feats, coords, device=device)\n",
    "\n",
    "    # Forward pass through encoder + head\n",
    "    _, cluster_batch = encoder(st, 1)\n",
    "    clust_probs = clust_head(cluster_batch)\n",
    "\n",
    "    # Select score\n",
    "    score = clust_probs[:, cluster_index].sum()\n",
    "\n",
    "    # Backprop\n",
    "    score.backward()\n",
    "\n",
    "    # Extract saliency\n",
    "    saliency = (feats * feats.grad).detach().cpu()\n",
    "    # saliency = feats.grad.detach().cpu()  # shape (N,1)\n",
    "    sal_coords = coords.cpu()\n",
    "    \n",
    "    return saliency, coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_grad(orig, encoder, clust_head, cluster_index, n_samples=50, sigma=0.2, device=device):\n",
    "    feats = orig.F.clone().detach().to(device)\n",
    "    coords = orig.C.to(device)\n",
    "    st_base = ME.SparseTensor(feats, coords, device=device)\n",
    "\n",
    "    total_grad = torch.zeros_like(feats)\n",
    "    for _ in range(n_samples):\n",
    "        noise = torch.randn_like(feats) * sigma\n",
    "        feats_noisy = (feats + noise).clone().detach().requires_grad_(True)\n",
    "        st_noisy = ME.SparseTensor(feats_noisy, coords, device=device)\n",
    "        _, cluster_batch = encoder(st_noisy, 1)\n",
    "        clust_probs = clust_head(cluster_batch)\n",
    "        score = clust_probs[:, cluster_index].sum()\n",
    "        score.backward()\n",
    "        total_grad += feats_noisy.grad\n",
    "\n",
    "    saliency = (total_grad / n_samples).detach().cpu()\n",
    "    return saliency, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from MinkowskiEngine import MinkowskiConvolution\n",
    "\n",
    "def find_last_conv(module):\n",
    "    for m in reversed(list(module.modules())):\n",
    "        if isinstance(m, MinkowskiConvolution):\n",
    "            return m\n",
    "    raise RuntimeError(\"No MinkowskiConvolution found\")\n",
    "    \n",
    "def grad_cam_sparse_hook(orig, encoder, clust_head, cluster_index, device='cpu'):\n",
    "    \"\"\"\n",
    "    Grad-CAM for MinkowskiEngine sparse tensors using forward hook.\n",
    "    \n",
    "    Args:\n",
    "        orig: ME.SparseTensor input\n",
    "        encoder: your encoder module\n",
    "        clust_head: classification head\n",
    "        cluster_index: class to compute CAM for\n",
    "        device: torch device\n",
    "    Returns:\n",
    "        cam_big: upsampled Grad-CAM numpy array\n",
    "    \"\"\"\n",
    "    # --- 1. Prepare input ---\n",
    "    feats = orig.F.clone().detach().to(device)\n",
    "    feats.requires_grad_(True)\n",
    "    coords = orig.C.clone().to(device)\n",
    "    orig_st = ME.SparseTensor(feats, coords, device=device)\n",
    "\n",
    "    # --- 2. Hook to capture features ---\n",
    "    saved = {}\n",
    "    def forward_hook(module, input, output):\n",
    "        # output is SparseTensor\n",
    "        saved['features'] = output.F\n",
    "        saved['coords'] = output.C\n",
    "        saved['output_tensor'] = output\n",
    "        saved['features'].retain_grad()\n",
    "\n",
    "    # Register hook on last conv layer of encoder\n",
    "    target_layer = find_last_conv(encoder.encoders)\n",
    "    handle = target_layer.register_forward_hook(forward_hook)\n",
    "    # handle = encoder.encoder_cnn[-1].register_forward_hook(forward_hook)\n",
    "\n",
    "    # --- 3. Forward pass ---\n",
    "    head_feats, cluster_batch = encoder(orig_st, batch_size=1, return_maps=False)\n",
    "    scores = clust_head(cluster_batch)\n",
    "    score = scores[:, cluster_index].sum()\n",
    "\n",
    "    # --- 4. Backward pass ---\n",
    "    encoder.zero_grad()\n",
    "    clust_head.zero_grad()\n",
    "    score.backward()\n",
    "\n",
    "    # --- 5. Grab gradients and compute weights ---\n",
    "    grads = saved['features'].grad  # (N, C)\n",
    "    if grads is None:\n",
    "        raise RuntimeError(\"Gradients not found! Make sure forward hook and retain_grad are working.\")\n",
    "\n",
    "    H=48\n",
    "    W=16\n",
    "    # Convert to dense for CAM computation\n",
    "    dense_maps, _, _ = saved['output_tensor'].dense(\n",
    "        shape=torch.Size([1, saved['features'].shape[1], H, W])\n",
    "    )\n",
    "    dense_grads, _, _ = saved['output_tensor'].dense(\n",
    "        shape=torch.Size([1, saved['features'].shape[1], H, W])\n",
    "    )\n",
    "    dense_grads = dense_grads.to(device)\n",
    "\n",
    "    # Compute channel weights (global average pooling over H,W)\n",
    "    weights = dense_grads.mean(dim=(2,3), keepdim=True)\n",
    "\n",
    "    # Compute Grad-CAM\n",
    "    cam = (weights * dense_maps).sum(dim=1, keepdim=True)\n",
    "    cam = torch.relu(cam)\n",
    "    cam = cam - cam.min()\n",
    "    if cam.max() > 0:\n",
    "        cam = cam / cam.max()\n",
    "\n",
    "    # Upsample to match original input resolution\n",
    "    cam_big = F.interpolate(cam, size=(768, 256), mode='nearest')\n",
    "    cam_big = cam_big[0,0].detach().cpu().numpy()\n",
    "\n",
    "    # --- 6. Cleanup ---\n",
    "    handle.remove()\n",
    "\n",
    "    return cam_big #[0,0].detach().cpu().numpy() #_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "def plot_saliency_block(dataset, encoder, clust_head, cluster_ids, cluster_index, max_x=10, cluster_probs=None, save_name=None): \n",
    "\n",
    "    ## Sort colours\n",
    "    cmap = cm.turbo.copy()\n",
    "    cmap.set_under(\"#F0F0F0\")\n",
    "\n",
    "    #cmap_sal = cm.PRGn.copy()\n",
    "    cmap_sal = cm.YlGn.copy()\n",
    "    # cmap_sal.set_under(\"#F0F0F0\")\n",
    "    \n",
    "    plt.figure(figsize=(max_x*2.1, 2*6))\n",
    "    ## Get a mask of cluster_ids\n",
    "    indices = np.arange(max_x*2) \n",
    "    if cluster_index != None: \n",
    "        indices = np.where(np.array(cluster_ids) == cluster_index)[0]\n",
    "        ## If the probabilities are given, show the top N probabilities\n",
    "        if cluster_probs is not None:\n",
    "            indices = indices[np.argsort(np.array(cluster_probs)[indices])][::-1]\n",
    "    max_images = min(len(indices), max_x)\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(2,max_x,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, *_ = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 768, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "\n",
    "        nonzero_vals = inputs[inputs > 0]\n",
    "        vmax = np.percentile(nonzero_vals, 80)\n",
    "        plt.imshow(inputs, origin='lower', cmap=cmap, vmin=1e-6, vmax=vmax)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        ax = plt.subplot(2,max_x,i+1+max_x)\n",
    "\n",
    "        # sal_feats, sal_coords = calc_saliency(orig, encoder, clust_head, cluster_index, device=device)\n",
    "        # sal_feats, sal_coords = smooth_grad(orig, encoder, clust_head, cluster_index, device=device)\n",
    "        outputs = grad_cam_sparse_hook(orig, encoder, clust_head, cluster_index, device=device)\n",
    "\n",
    "        #sal = ME.SparseTensor(sal_feats, sal_coords, device='cpu')\n",
    "\n",
    "        #outputs  = make_dense_from_tensor(sal, 0, 768, 256)\n",
    "        #outputs  = outputs .cpu().squeeze().numpy()    \n",
    "\n",
    "        # print(np.isnan(outputs).any(), np.isinf(outputs).any(), outputs.min(), outputs.max())\n",
    "\n",
    "        vmax = outputs.max()\n",
    "        if abs(outputs.min()) > vmax: vmax = abs(outputs.min())\n",
    "        \n",
    "        plt.imshow(outputs, origin='lower', cmap=cmap_sal, vmin=1E-8, vmax=vmax)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        #sal_feats, sal_coords = smooth_grad(orig, encoder, clust_head, cluster_index, device=device)\n",
    "        #sal = ME.SparseTensor(sal_feats, sal_coords, device='cpu')\n",
    "\n",
    "        #sal_outputs  = make_dense_from_tensor(sal, 0, 768, 256)\n",
    "        # sal_outputs  = outputs .cpu().squeeze().numpy()    \n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def process_max_val(max_val):\n",
    "    if isinstance(max_val, (list, tuple)):\n",
    "        if len(max_val) == 2:\n",
    "            x, y = max_val\n",
    "        elif len(max_val) == 1:\n",
    "            x, y = max_val[0], 1\n",
    "        else:\n",
    "            raise ValueError(\"max_val list/tuple must have 1 or 2 elements\")\n",
    "    else:\n",
    "        # single scalar value\n",
    "        x, y = max_val, 1\n",
    "    return x, y\n",
    "\n",
    "def plot_saliency_overlay_block(dataset, encoder, clust_head, cluster_ids, cluster_index, max_val=10, cluster_probs=None, save_name=None): \n",
    "\n",
    "    ## Sort colours\n",
    "    cmap = cm.turbo.copy()\n",
    "    #cmap.set_under(\"#F0F0F0\")\n",
    "\n",
    "    #cmap_sal = cm.PRGn.copy()\n",
    "    cmap_sal = cm.spring.copy()\n",
    "    cmap_sal.set_under(\"#F0F0F0\")\n",
    "    max_x, max_y = process_max_val(max_val)\n",
    "    \n",
    "    plt.figure(figsize=(max_x*2.1, max_y*6))\n",
    "    ## Get a mask of cluster_ids\n",
    "    indices = np.arange(max_x*max_y) \n",
    "    if cluster_index != None: \n",
    "        indices = np.where(np.array(cluster_ids) == cluster_index)[0]\n",
    "        ## If the probabilities are given, show the top N probabilities\n",
    "        if cluster_probs is not None:\n",
    "            indices = indices[np.argsort(np.array(cluster_probs)[indices])][::-1]\n",
    "    max_images = min(len(indices), max_x*max_y)\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(max_y,max_x,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, *_ = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 768, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        #img = inputs\n",
    "        inputs = (inputs - inputs.min()) / (inputs.max() - inputs.min() + 1e-8)\n",
    "\n",
    "        rgba_inputs = np.zeros((*inputs.shape, 4), dtype=np.float32)\n",
    "        rgba_inputs[..., 0] = inputs  # R\n",
    "        rgba_inputs[..., 1] = inputs  # G\n",
    "        rgba_inputs[..., 2] = inputs  # B\n",
    "        rgba_inputs[..., 3] = (inputs > 0).astype(np.float32)  # alpha: 0 if zero, 1 if nonzero\n",
    "        \n",
    "        outputs = grad_cam_sparse_hook(orig, encoder, clust_head, cluster_index, device=device)\n",
    "\n",
    "        cam = outputs\n",
    "        # Normalize CAM\n",
    "        cam_norm = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        heatmap = plt.cm.YlGn(cam_norm)[:, :, :3]\n",
    "\n",
    "        nonzero_vals = inputs[inputs > 0]\n",
    "        vmax = np.percentile(nonzero_vals, 80)\n",
    "        # plt.imshow(inputs, origin='lower', cmap=cmap, vmin=1e-6, vmax=vmax)\n",
    "        plt.imshow(outputs, origin='lower', cmap=cmap_sal, alpha=0.8, vmin=1E-8, vmax=vmax)\n",
    "        plt.imshow(rgba_inputs, origin='lower') #, cmap=cmap, vmin=0, vmax=vmax)\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clust in range(30):\n",
    "    print(\"Saliency for cluster\", clust)\n",
    "    plot_saliency_overlay_block(data_dataset, encoder, heads[\"clust\"], data_processed['clust_index'], clust, [8,2], cluster_probs=data_processed['clust_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
