{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bootstrap\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import MinkowskiEngine as ME\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "## Tell pytorch we have a GPU if we do\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "torch.device(device)\n",
    "\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)\n",
    "writer = SummaryWriter(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Includes from my libraries for this project                                                                                                                                           \n",
    "from core.losses.ntxent import NTXentMerged\n",
    "from core.losses.clustering import ClusteringLossMerged\n",
    "from core.models.projection_head import ProjectionHeadLogits\n",
    "from core.models.clustering_head import ClusteringHeadOneLayer, ClusteringHeadTwoLayer\n",
    "from core.models.encoder import CCEncoderFSD12x4Opt, CCEncoderFSD24x8Opt       \n",
    "\n",
    "## Import transformations                                                                                                                                                                \n",
    "from core.data.augmentations_2d import CenterCrop, DoNothing\n",
    "from datasets.fsd.augmentations_2d import get_transform\n",
    "\n",
    "## Import dataset                                                                                                                                                                        \n",
    "from core.data.datasets import paired_2d_dataset_ME, cat_ME_collate_fn\n",
    "from core.data.datasets import single_2d_dataset_ME, solo_ME_collate_fn\n",
    "\n",
    "## For later visualization\n",
    "from core.analysis.image_utils import make_dense_from_tensor\n",
    "\n",
    "from core.analysis.metrics import argmax_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def sharpen(p, temperature=0.5):\n",
    "    p_power = p ** (1.0 / temperature)\n",
    "    return p_power / p_power.sum(dim=1, keepdim=True)\n",
    "\n",
    "def run_training(num_iterations, log_dir, encoder, proj_head, clust_head, temperature, dataloader, optimizer, batch_size, scheduler=None, entropy_weight=1.0):\n",
    "\n",
    "    print(\"Training with\", num_iterations, \"iterations\")\n",
    "    tstart = time.process_time()\n",
    "\n",
    "    if log_dir: writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    instance_loss_fn = NTXentMerged(temperature)\n",
    "    cluster_loss_fn  = ClusteringLossMerged(temperature, entropy_weight=entropy_weight)\n",
    "    \n",
    "    encoder.to(device)\n",
    "    proj_head.to(device)\n",
    "    clust_head.to(device)\n",
    "    \n",
    "    ## Loop over the desired iterations\n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_instance_loss = 0\n",
    "        total_cluster_loss = 0\n",
    "\n",
    "        total_entropy_loss = 0\n",
    "        total_acc = 0\n",
    "        nbatches   = 0\n",
    "        \n",
    "        # Set train mode for both the encoder and the decoder\n",
    "        encoder.train()\n",
    "        proj_head.train()\n",
    "        clust_head.train()\n",
    "        \n",
    "        # Iterate over batches of images with the dataloader\n",
    "        for cat_bcoords, cat_bfeats, this_batch_size in train_loader:\n",
    "            \n",
    "            ## Send to the device, then make the sparse tensors                                                                                                                          \n",
    "            cat_bcoords = cat_bcoords.to(device, non_blocking=True)\n",
    "            cat_bfeats  = cat_bfeats .to(device)\n",
    "            cat_batch   = ME.SparseTensor(cat_bfeats, cat_bcoords, device=device)\n",
    "\n",
    "            ## Now do the forward pass     \n",
    "            encoded_instance_batch, encoded_cluster_batch = encoder(cat_batch, this_batch_size)\n",
    "            proj_batch = proj_head(encoded_instance_batch)\n",
    "            clust_batch = clust_head(encoded_cluster_batch)\n",
    "            \n",
    "            total_acc += argmax_consistency(clust_batch, device).item()\n",
    "            # sharpened_batch = sharpen(clust_batch, temperature=0.5)\n",
    "            \n",
    "            # Evaluate loss, but sw\n",
    "            instance_loss = instance_loss_fn(proj_batch)\n",
    "            clust_loss, clust_entropy = cluster_loss_fn(clust_batch)\n",
    "            loss = instance_loss + clust_loss + clust_entropy\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_instance_loss += instance_loss.item()\n",
    "            total_cluster_loss += clust_loss.item()\n",
    "            total_entropy_loss += clust_entropy.item()\n",
    "            nbatches += 1\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        ## See if we have an LR scheduler...\n",
    "        if scheduler: scheduler.step(total_loss)\n",
    "        \n",
    "        av_loss = total_loss/nbatches\n",
    "\n",
    "        if log_dir: writer.add_scalar('loss/train', av_loss, iteration)\n",
    "        print(\"Processed\", iteration, \"/\", num_iterations, \"; loss =\", av_loss, \"(\", total_instance_loss/nbatches, \\\n",
    "              total_cluster_loss/nbatches, total_entropy_loss/nbatches,\");\", \"acc =\", total_acc/nbatches)\n",
    "        print(\"Time taken:\", time.process_time() - tstart)\n",
    "        \n",
    "        ## End so empty cache because MinkowskiEngine can't be trusted\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.data import ConcatDataset\n",
    "start = time.process_time() \n",
    "\n",
    "## Get a set of augmentations to use in training\n",
    "aug_transform = get_transform('fsd', 'baseaug')\n",
    "\n",
    "## Make a mixed dataset of data and simulation\n",
    "data_dir = \"/pscratch/sd/c/cwilk/FSD/DATA\"\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/FSD/SIMULATION\"\n",
    "data_dataset = paired_2d_dataset_ME(data_dir, nom_transform=DoNothing(), aug_transform=aug_transform, max_events=100000)\n",
    "sim_dataset  = paired_2d_dataset_ME(sim_dir, nom_transform=DoNothing(), aug_transform=aug_transform, max_events=50000)\n",
    "mixed_dataset = data_dataset #ConcatDataset([data_dataset, sim_dataset])\n",
    "print(\"Loaded:\", data_dataset.__len__(), \"data and\", sim_dataset.__len__(), \"simulated events\")\n",
    "\n",
    "batch_size=1024\n",
    "train_loader = torch.utils.data.DataLoader(mixed_dataset,\n",
    "                                           collate_fn=cat_ME_collate_fn,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=8,\n",
    "                                           drop_last=True,\n",
    "                                           pin_memory=False,\n",
    "                                           prefetch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This is a useful but experimental pytorch function which flags where synchronization calls are made\n",
    "## (useful for debugging only)\n",
    "from torch import optim\n",
    "\n",
    "## Varius config parameters\n",
    "nchan=24\n",
    "nhidden=256\n",
    "nlatent=64\n",
    "enc_act_fn=ME.MinkowskiSiLU\n",
    "hidden_act_fn=nn.SiLU\n",
    "latent_act_fn=nn.Tanh\n",
    "dropout = 0\n",
    "temperature = 0.5\n",
    "num_iterations=50\n",
    "log_dir=\"log_jupyter\"\n",
    "nclusters = 50\n",
    "first_kernel = 7\n",
    "flatten = 1\n",
    "pool = \"max\"\n",
    "slow_growth = 1\n",
    "sep_heads = 0\n",
    "softmax_temp=1.0\n",
    "entropy_weight=0.1\n",
    "\n",
    "## Define the models\n",
    "encoder=CCEncoderFSD24x8Opt(nchan, \\\n",
    "                  act_fn=enc_act_fn, \\\n",
    "                  first_kernel=first_kernel, \\\n",
    "                  flatten=True, \\\n",
    "                  pool=pool, \\\n",
    "                  slow_growth=bool(slow_growth),\n",
    "                  sep_heads=True)\n",
    "proj_head = ProjectionHeadLogits(encoder.get_nchan_instance(), nlatent, nhidden, hidden_act_fn)\n",
    "clust_head = ClusteringHeadTwoLayer(encoder.get_nchan_cluster(), nclusters, softmax_temp)\n",
    "\n",
    "## Load in the pre-calculated model weights if they exist\n",
    "chk_file=None \n",
    "if chk_file:\n",
    "    checkpoint = torch.load(chk_file, map_location='cpu')\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "\n",
    "encoder.to(device)\n",
    "proj_head.to(device)\n",
    "clust_head.to(device)\n",
    "\n",
    "params_to_optimize = [\n",
    "        {'params': encoder.parameters()},\n",
    "        {'params': proj_head.parameters()},\n",
    "        {'params': clust_head.parameters()},\n",
    "    ]\n",
    "\n",
    "lr=5e-4\n",
    "weight_decay=0 #1e-5\n",
    "optimizer = torch.optim.AdamW(params_to_optimize, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "## Scheduler options\n",
    "scheduler = None \n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "#                                                 mode='min',\n",
    "#                                                 factor=0.2,\n",
    "#                                                 patience=1,\n",
    "#                                                 cooldown=2,\n",
    "#                                                 threshold=5e-3,\n",
    "#                                                 threshold_mode='rel')\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=num_iterations, cycle_momentum=False)\n",
    "\n",
    "run_training(num_iterations, log_dir, encoder, proj_head, clust_head, temperature, train_loader, optimizer, batch_size, scheduler, entropy_weight=entropy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.data.datasets import single_2d_dataset_ME, solo_ME_collate_fn\n",
    "from core.data.augmentations_2d import MaxRegionCrop, FirstRegionCrop\n",
    "\n",
    "## Make a single loader to loop over for ease\n",
    "max_transform = FirstRegionCrop((800, 256), (768, 256))\n",
    "single_sim_dataset = single_2d_dataset_ME(sim_dir, transform=max_transform, max_events=100000) #nevents)\n",
    "single_data_dataset = single_2d_dataset_ME(data_dir, transform=max_transform, max_events=100000) #nevents)\n",
    "\n",
    "single_mixed_dataset = ConcatDataset([single_data_dataset, single_sim_dataset])\n",
    "#single_mixed_dataset = single_sim_dataset\n",
    "\n",
    "single_loader = torch.utils.data.DataLoader(single_mixed_dataset,\n",
    "                                            collate_fn=solo_ME_collate_fn,\n",
    "                                            batch_size=512,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "\n",
    "cluster = []\n",
    "latent = []\n",
    "nhits  = []\n",
    "labels = []\n",
    "\n",
    "## Make this work with batches larger than 1...\n",
    "for orig_bcoords, orig_bfeats, blabels in single_loader:\n",
    "\n",
    "    batch_size = len(blabels)\n",
    "    # print(type(blabels), len(blabels))\n",
    "\n",
    "    orig_bcoords = orig_bcoords.to(device)\n",
    "    orig_bfeats = orig_bfeats.to(device)\n",
    "    orig_batch = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)            \n",
    "                                            \n",
    "    ## Now do the forward passes            \n",
    "    encoder.eval()\n",
    "    clust_head.eval()\n",
    "    proj_head.eval()\n",
    "    with torch.no_grad(): \n",
    "        encoded_instance_batch, encoded_cluster_batch = encoder(orig_batch, batch_size)\n",
    "        proj_batch = proj_head(encoded_instance_batch)\n",
    "        clust_batch = clust_head(encoded_cluster_batch)\n",
    "    \n",
    "    nhits += [i.shape[0] for i in orig_batch.decomposed_features] # if i.shape[0] != 0] \n",
    "    cluster += [x[np.newaxis, :] for x in clust_batch.detach().cpu().numpy()]\n",
    "    latent += [x[np.newaxis, :] for x in proj_batch.detach().cpu().numpy()]\n",
    "    labels += [x for x in blabels]\n",
    "    \n",
    "latent_vect = np.vstack(latent)\n",
    "cluster_vect = np.vstack(cluster)\n",
    "hit_vect = np.array(nhits)\n",
    "label_vect = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_index = np.argmax(cluster_vect, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = np.max(cluster_vect, axis=1)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(max_values, bins=50, edgecolor='black')\n",
    "plt.xlabel('Maximum value (per row)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of maximum values across 20 features')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = np.argmax(cluster_vect, axis=1)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(max_indices, bins=np.arange(nclusters+1)-0.5, edgecolor='black')\n",
    "plt.xlabel('Index of max value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of max indices')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload so I can play with changes outside jupyter...\n",
    "import importlib\n",
    "import analysis.plotting_utils\n",
    "importlib.reload(analysis.plotting_utils)\n",
    "from analysis.plotting_utils import compute_cluster_overlap, plot_overlap_matrix\n",
    "\n",
    "overlap_matrix = compute_cluster_overlap(cluster_vect, 4)\n",
    "plot_overlap_matrix(overlap_matrix, max_val=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def __compute_cluster_centroids(embeddings, assignments, n_clusters):\n",
    "    D = embeddings.shape[1]\n",
    "    centroids = np.zeros((n_clusters, D), dtype=np.float32)\n",
    "\n",
    "    for k in range(n_clusters):\n",
    "        mask = (assignments == k)\n",
    "        if mask.any():\n",
    "            centroids[k] = embeddings[mask].mean(axis=0)\n",
    "        else:\n",
    "            centroids[k] = np.nan  # empty cluster\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def compute_cluster_centroids(X, labels):\n",
    "    centroids = []\n",
    "    for k in np.unique(labels):\n",
    "        members = X[labels == k]\n",
    "        centroids.append(members.mean(axis=0))\n",
    "    return np.vstack(centroids)\n",
    "    \n",
    "def compute_centroid_similarity(centroids, metric=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Compute pairwise similarity/distance between centroids.\n",
    "\n",
    "    Args:\n",
    "        centroids: (K, D) array\n",
    "        metric: \"cosine\" (similarity) or \"euclidean\" (distance)\n",
    "\n",
    "    Returns:\n",
    "        sim_matrix: (K, K) array of similarities/distances\n",
    "    \"\"\"\n",
    "    mask = ~np.isnan(centroids).any(axis=1)\n",
    "    centroids_valid = centroids[mask]\n",
    "\n",
    "    print(centroids_valid.shape)\n",
    "    if metric == \"cosine\":\n",
    "        sim_matrix = cosine_similarity(centroids_valid)\n",
    "    elif metric == \"euclidean\":\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        sim_matrix = -pairwise_distances(centroids_valid, metric=\"euclidean\")  # negative so higher=closer\n",
    "    else:\n",
    "        raise ValueError(\"metric must be 'cosine' or 'euclidean'\")\n",
    "    \n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = compute_cluster_centroids(cluster_vect, clust_index) #, 30)\n",
    "sim_matrix = compute_centroid_similarity(centroids)\n",
    "plt.imshow(centroids, cmap=\"viridis\", vmin=-0.2, vmax=0.2) \n",
    "#plot_overlap_matrix(centroids) #sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Make a plot of what it looks like\n",
    "plt.scatter(latent_vect[:,0], latent_vect[:,1], s=1, c=clust_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(clust_index, label_vect, bins=[10, 20], range=[[0, 10], [0, 20]])\n",
    "\n",
    "# Plot it\n",
    "plt.imshow(H.T, origin='lower', aspect='auto', cmap='viridis')  # Note the .T to match axes\n",
    "plt.colorbar(label='Count')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('clust_index')\n",
    "#plt.xticks(np.arange(20))\n",
    "#plt.yticks(np.arange(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cuml.manifold import TSNE as cuML_TSNE\n",
    "import cupy as cp\n",
    "\n",
    "## Define a function for running t-SNE using the cuml version\n",
    "def run_tsne_cuml(perp=300, exag=100, input_vect=latent_vect, nhits=clust_index):\n",
    "    print(\"Running cuML t-SNE with: perplexity =\", perp, \"early exaggeration =\", exag)\n",
    "    \n",
    "    input_vect = cp.asarray(input_vect, dtype=cp.float32)\n",
    "\n",
    "    ## I haven't played with most of cuml's t-SNE parameters\n",
    "    tsne = cuML_TSNE(n_components=2, perplexity=perp, n_neighbors=4*perp, n_iter=1000, early_exaggeration=exag, late_exaggeration=1, metric='cosine') #, learning_rate=100, n_neighbors=1000)\n",
    "    tsne_results = tsne.fit_transform(input_vect)\n",
    "\n",
    "    tsne_results = cp.asnumpy(tsne_results)  # Convert to NumPy for matplotlib\n",
    "\n",
    "    # gr = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.2, alpha=0.8, vmin=100, vmax=500, c=nhits)\n",
    "    gr = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.2, alpha=0.8, c=nhits)\n",
    "    plt.colorbar(gr, label='N.hits')\n",
    "    plt.xlabel('t-SNE #0')\n",
    "    plt.ylabel('t-SNE #1')\n",
    "    plt.show()\n",
    "\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually run t-SNE\n",
    "perp=30\n",
    "exag=10\n",
    "tsne_results = run_tsne_cuml(perp, exag, latent_vect, clust_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to show examples for each cluster\n",
    "def plot_cluster_examples(dataset, labels, index, max_images=10): \n",
    "    \n",
    "    plt.figure(figsize=(15,9))\n",
    "\n",
    "    ## Get a mask of labels\n",
    "    indices = np.where(np.array(labels) == index)[0]\n",
    "    \n",
    "    ## Grab the first 10 images (if there are 10)\n",
    "    if len(indices) < max_images:\n",
    "        max_images = len(indices)\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(2,max_images,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, label = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "\n",
    "        orig_bcoords = orig_bcoords.to(device)\n",
    "        orig_bfeats = orig_bfeats.to(device)\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 768, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        \n",
    "        plt.imshow(inputs, origin='lower')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)            \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now pull out a bank of example images for each cluster\n",
    "\n",
    "for index in range(nclusters):\n",
    "    print(\"Showing examples for cluster:\", index, \"which has\", np.count_nonzero(clust_index==index), \"values\")\n",
    "    plot_cluster_examples(single_mixed_dataset, clust_index, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to show a big block of examples for each cluster\n",
    "## index == None will just give an unclustered set\n",
    "def plot_cluster_bigblock(dataset, clust_index, index, max_x=10, max_y=10, save_name=None): \n",
    "    \n",
    "    plt.figure(figsize=(max_y*2, max_x*1.8*2))\n",
    "    ## Get a mask of cluster_ids\n",
    "    indices = np.arange(max_x*max_y) \n",
    "    if index != None: indices = np.where(np.array(clust_index) == index)[0]\n",
    "    max_images = min(len(indices), max_x*max_y)\n",
    "    print(len(indices))\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(max_x,max_y,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, _ = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "\n",
    "        orig_bcoords = orig_bcoords.to(device)\n",
    "        orig_bfeats = orig_bfeats.to(device)\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 768, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        \n",
    "        plt.imshow(inputs, origin='lower')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)    \n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=150, bbox_inches='tight')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dump out a large block of images for one cluster\n",
    "plot_cluster_bigblock(single_mixed_dataset, clust_index, 8, 10, 10) #, 'cluster_plots/v9_michel_like.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
