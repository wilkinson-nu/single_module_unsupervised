{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bootstrap\n",
    "import MinkowskiEngine as ME\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "## Tell pytorch we have a GPU if we do\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Use the common dataset loader\n",
    "from core.data.datasets import paired_2d_dataset_ME, triple_ME_collate_fn\n",
    "from core.analysis.image_utils import make_dense, make_dense_from_tensor, make_dense_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "## This function just pulls an image directly from the file, without going through a pytorch dataloder\n",
    "## You would need to have a file open: f = h5py.File(input_file, 'r')\n",
    "def show_image(i, f):\n",
    "    group = f[str(i)]\n",
    "    data = group['data'][:]\n",
    "    row = group['row'][:]\n",
    "    col = group['col'][:]\n",
    "\n",
    "    ## Use the format that ME requires                                                                                                                                                                         \n",
    "\t## Note that we can't build the sparse tensor here because ME uses some sort of global indexing                                                                                                            \n",
    "\t## And this function is replicated * num_workers                                                                                                                                                           \n",
    "    this_sparse = coo_matrix((data, (row, col)), dtype=np.float32, shape=(800, 256))    \n",
    "    this_image = this_sparse.toarray()\n",
    "\n",
    "    gr = plt.imshow(this_image, origin='lower')\n",
    "    plt.colorbar(gr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "# Force reload so I can play with changes outside jupyter...\n",
    "import importlib\n",
    "import core.data.augmentations_2d\n",
    "importlib.reload(core.data.augmentations_2d)\n",
    "import core.data.augmentations_2d as aug\n",
    "import datasets.nularbox.augmentations_2d\n",
    "importlib.reload(datasets.nularbox.augmentations_2d)\n",
    "import datasets.nularbox.augmentations_2d as nu_aug\n",
    "\n",
    "x_max=256\n",
    "y_max=256\n",
    "\n",
    "x_orig=512\n",
    "y_orig=512\n",
    "\n",
    "aug_prob=1\n",
    "\n",
    "mod_transform = transforms.Compose([\n",
    "    \t    aug.RandomBlockZeroImproved([5,20], [5,10], [0,x_orig], [0,y_orig], p=aug_prob),\n",
    "            aug.RandomBlockZeroImproved([50,200], [1,3], [0,x_orig], [0,y_orig], p=aug_prob),\n",
    "            aug.RandomVerticalFlip(y_max=y_orig, p=0.5),\n",
    "            aug.GridJitter(),\n",
    "            aug.JitterCoords(),\n",
    "            nu_aug.RandomCentralRotation2D(30, img_size=[y_orig, x_orig], frac=0.2, p=aug_prob),\n",
    "            nu_aug.RandomCentralShear2D(0.2, 0.2, img_size=[y_orig, x_orig], frac=0.4, p=aug_prob),\n",
    "            nu_aug.RandomCentralStretch2D(0.1, 0.1, img_size=[y_orig, x_orig], frac=0.4, p=aug_prob),\n",
    "    \t    aug.RandomGridDistortion2D(50, 4, 2, 10, p=aug_prob),\n",
    "    \t    aug.RandomScaleCharge(0.05, p=aug_prob),\n",
    "        \taug.RandomJitterCharge(0.05, p=aug_prob),\n",
    "    \t    aug.BilinearSplatMod(0.2, 0.3, p=aug_prob),            \n",
    "            nu_aug.RandomCenterCrop([y_orig,x_orig], [y_max,x_max], 10)\n",
    "            ])\n",
    "\n",
    "aug_transform = mod_transform\n",
    "\n",
    "## Load some images into a data loader\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/NULARBOX/GENIE10a_512x512\"\n",
    "\n",
    "nom_transform = transforms.Compose([\n",
    "            aug.DoNothing(),\n",
    "            ])\n",
    "\n",
    "sim_dataset = paired_2d_dataset_ME(sim_dir, nom_transform=nom_transform, aug_transform=aug_transform, max_events=100000)\n",
    "print(\"Found\", sim_dataset.__len__(), \"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def profile_transforms_avg(dataset, transform_block, n_events=10):\n",
    "    times_accum = {t.__class__.__name__: [] for t in transform_block.transforms}\n",
    "\n",
    "    for idx in range(n_events):\n",
    "        _, _, _, _, coords, feats = dataset[idx]\n",
    "        for t in transform_block.transforms:\n",
    "            start = time.perf_counter()\n",
    "            coords, feats = t(coords, feats)\n",
    "            end = time.perf_counter()\n",
    "            times_accum[t.__class__.__name__].append(end - start)\n",
    "\n",
    "    times_avg = {k: np.mean(v) for k, v in times_accum.items()}\n",
    "    return times_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = profile_transforms_avg(sim_dataset, mod_transform, n_events=1000)\n",
    "times_sorted = sorted(times.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for name, t in times_sorted:\n",
    "    print(f\"{name:30s}: {t*1000:.3f} ms\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_aug_comp_plot(dataset, ids=[0], save_name=None):\n",
    "\n",
    "    cmap = cm.turbo.copy()\n",
    "    cmap.set_under(\"#F0F0F0\")\n",
    "\n",
    "    # Visualize the image\n",
    "    n_augs = 5\n",
    "    n_ids = len(ids)\n",
    "    indices = np.arange(n_augs*n_ids)\n",
    "\n",
    "    ## Set up the canvas\n",
    "    plt.figure(figsize=(n_augs*2.1, n_ids*6))\n",
    "\n",
    "    ## To keep track of the subplot\n",
    "    running_n = 0\n",
    "    \n",
    "    ## Loop over images\n",
    "    for i in ids:\n",
    "    \n",
    "        ## The dataset works with pairs, so this is just a bit hacky to get more examples\n",
    "        aug1_bcoords, aug1_bfeats, aug2_bcoords, aug2_bfeats, orig_bcoords, orig_bfeats = dataset[i]\n",
    "        aug3_bcoords, aug3_bfeats, aug4_bcoords, aug4_bfeats, _, _ = dataset[i]\n",
    "\n",
    "        ## Keep the same scale for them all\n",
    "        #orig_max = max(orig_bfeats)\n",
    "        \n",
    "        augs = [make_dense_array(orig_bcoords, orig_bfeats.squeeze(), y_orig, x_orig),\n",
    "                make_dense_array(aug1_bcoords, aug1_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug2_bcoords, aug2_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug3_bcoords, aug3_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug4_bcoords, aug4_bfeats.squeeze(), y_max, x_max)]\n",
    "\n",
    "        orig_max = augs[0].max()\n",
    "        orig = augs[0]\n",
    "        #print(\"orig_min =\", np.min(orig[orig != 0]))\n",
    "        \n",
    "        ## Loop over augmentations\n",
    "        for aug in augs:\n",
    "            ax = plt.subplot(n_ids,n_augs,running_n+1)\n",
    "            # mean_val = np.mean(aug[np.isfinite(aug)]) \n",
    "            mean_val = np.mean(aug[aug != 0])\n",
    "            #print(running_n, mean_val)\n",
    "            nonzero_vals = aug[aug > 0]\n",
    "            vmax = np.percentile(nonzero_vals, 80)\n",
    "            ax.imshow(aug, origin='lower', cmap=cmap, vmin=1e-6, vmax=vmax) #, vmax=orig_max)\n",
    "            ax.axis('off')\n",
    "            running_n += 1\n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for evt in range(50):\n",
    "    make_aug_comp_plot(sim_dataset, ids=[evt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
