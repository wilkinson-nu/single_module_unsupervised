{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import MinkowskiEngine as ME\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "## Tell pytorch we have a GPU if we do\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "torch.device(device)\n",
    "\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)\n",
    "writer = SummaryWriter(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Includes from my libraries for this project                                                                                                                                           \n",
    "from ME_NN_libs import NTXentMerged, ContrastiveEncoderME\n",
    "\n",
    "## Import transformations                                                                                                                                                                \n",
    "from ME_dataset_libs import CenterCrop, get_transform\n",
    "\n",
    "## Import dataset                                                                                                                                                                        \n",
    "from ME_dataset_libs import SingleModuleImage2D_MultiHDF5_ME, cat_ME_collate_fn\n",
    "from ME_dataset_libs import SingleModuleImage2D_solo_ME, solo_ME_collate_fn\n",
    "\n",
    "## For later visualization\n",
    "from ME_dataset_libs import make_dense_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveEncoderShallowME(nn.Module):\n",
    "    def __init__(self, \n",
    "                 nchan : int,\n",
    "                 latent_dim : int,\n",
    "                 batch_size : int,\n",
    "                 hidden_act_fn : object = ME.MinkowskiReLU,\n",
    "                 latent_act_fn : object = ME.MinkowskiTanh,\n",
    "                 drop_fract : float = 0,\n",
    "                 conv_kernel_size=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ch = [nchan, nchan*2, nchan*4, nchan*8, nchan*16]\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Convolutional section â€” down to 8x4\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            ME.MinkowskiConvolution(1, self.ch[0], kernel_size=self.conv_kernel_size, stride=2, bias=False, dimension=2), # 256x128 -> 128x64\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[0], self.ch[0], kernel_size=3, bias=False, dimension=2),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[0], self.ch[1], kernel_size=self.conv_kernel_size, stride=2, bias=False, dimension=2), # 128x64 -> 64x32\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[1], self.ch[1], kernel_size=3, bias=False, dimension=2),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[1], self.ch[2], kernel_size=self.conv_kernel_size, stride=2, bias=False, dimension=2), # 64x32 -> 32x16\n",
    "            ME.MinkowskiBatchNorm(self.ch[2]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[2], self.ch[2], kernel_size=3, bias=False, dimension=2),\n",
    "            ME.MinkowskiBatchNorm(self.ch[2]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[2], self.ch[3], kernel_size=self.conv_kernel_size, stride=2, bias=False, dimension=2), # 32x16 -> 16x8\n",
    "            ME.MinkowskiBatchNorm(self.ch[3]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[3], self.ch[3], kernel_size=3, bias=False, dimension=2),\n",
    "            ME.MinkowskiBatchNorm(self.ch[3]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[3], self.ch[4], kernel_size=self.conv_kernel_size, stride=2, bias=False, dimension=2), # 16x8 -> 8x4\n",
    "            ME.MinkowskiBatchNorm(self.ch[4]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "            ME.MinkowskiConvolution(self.ch[4], self.ch[4], kernel_size=3, bias=False, dimension=2),\n",
    "            ME.MinkowskiBatchNorm(self.ch[4]),\n",
    "            hidden_act_fn(),\n",
    "            ME.MinkowskiDropout(drop_fract),\n",
    "        )\n",
    "\n",
    "        # We'll flatten after this to shape [B, C * 16 * 8]\n",
    "        self.feature_channels = self.ch[4]\n",
    "        self.spatial_shape = torch.Size([self.batch_size, self.feature_channels, 8, 4])  # Final feature map shape\n",
    "        self.to_dense = ME.MinkowskiToDenseTensor(shape=self.spatial_shape)\n",
    "        \n",
    "        # Linear projection head (pure PyTorch)\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(self.feature_channels*8*4, self.feature_channels),\n",
    "            nn.BatchNorm1d(self.feature_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(drop_fract),\n",
    "            nn.Linear(self.feature_channels, self.feature_channels//4),\n",
    "            nn.BatchNorm1d(self.feature_channels//4),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(drop_fract),\n",
    "            nn.Linear(self.feature_channels//4, latent_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, ME.MinkowskiConvolution):\n",
    "                ME.utils.kaiming_normal_(m.kernel, mode=\"fan_out\", nonlinearity=\"linear\")\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=\"linear\")\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        # Convert sparse tensor to dense\n",
    "        dense = self.to_dense(x)\n",
    "        flat = dense.flatten(start_dim=1)     # [B, C * 8 * 4]\n",
    "        out = self.encoder_lin(flat)          # Final embedding\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training function\n",
    "def run_training(num_iterations, log_dir, encoder, temperature, dataloader, optimizer, batch_size, scheduler=None):\n",
    "\n",
    "    print(\"Training with\", num_iterations, \"iterations\")\n",
    "    tstart = time.process_time()\n",
    "\n",
    "    if log_dir: writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    loss_fn = NTXentMerged(temperature)\n",
    "\n",
    "    encoder.to(device)\n",
    "    \n",
    "    ## Loop over the desired iterations\n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        total_loss = 0\n",
    "        nbatches   = 0\n",
    "        \n",
    "        # Set train mode for both the encoder and the decoder\n",
    "        encoder.train()\n",
    "        \n",
    "        # Iterate over batches of images with the dataloader\n",
    "        for cat_bcoords, cat_bfeats in train_loader:\n",
    "\n",
    "            ## Send to the device, then make the sparse tensors                                                                                                                          \n",
    "            cat_bcoords = cat_bcoords.to(device, non_blocking=True)\n",
    "            cat_bfeats  = cat_bfeats .to(device)\n",
    "            cat_batch   = ME.SparseTensor(cat_bfeats, cat_bcoords, device=device)\n",
    "\n",
    "            ## Now do the forward pass                                                                                                                                                 \n",
    "            encoded_batch = encoder(cat_batch)\n",
    "     \n",
    "            # Evaluate loss, but sw\n",
    "            if hasattr(encoded_batch, 'F'): loss = loss_fn(encoded_batch.F)\n",
    "            else: loss = loss_fn(encoded_batch)\n",
    "            # loss = loss_fn(encoded_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            nbatches += 1\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        ## See if we have an LR scheduler...\n",
    "        if scheduler: scheduler.step() #total_loss)\n",
    "        \n",
    "        av_loss = total_loss/nbatches\n",
    "\n",
    "        if log_dir: writer.add_scalar('loss/train', av_loss, iteration)\n",
    "        print(\"Processed\", iteration, \"/\", num_iterations, \"; loss =\", av_loss)\n",
    "        print(\"Time taken:\", time.process_time() - tstart)\n",
    "        \n",
    "        ## End so empty cache because MinkowskiEngine can't be trusted\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "aug_transform = get_transform('block10x10')\n",
    "\n",
    "inDir = \"/pscratch/sd/c/cwilk/h5_inputs_v9/\"\n",
    "start = time.process_time() \n",
    "train_dataset = SingleModuleImage2D_MultiHDF5_ME(inDir, nom_transform=CenterCrop(), aug_transform=aug_transform, max_events=100000)\n",
    "print(\"Time taken to load\", train_dataset.__len__(),\"images:\", time.process_time() - start)\n",
    "\n",
    "batch_size=512\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           collate_fn=cat_ME_collate_fn,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=8,\n",
    "                                           drop_last=True,\n",
    "                                           pin_memory=False,\n",
    "                                           prefetch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This is a useful but experimental pytorch function which flags where synchronization calls are made\n",
    "## (useful for debugging only)\n",
    "# import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "## Varius config parameters\n",
    "nchan=32\n",
    "nlatent=128\n",
    "hidden_act_fn=ME.MinkowskiSiLU\n",
    "latent_act_fn=ME.MinkowskiTanh\n",
    "dropout = 0\n",
    "temperature = 0.5\n",
    "num_iterations=50\n",
    "log_dir=\"log\"\n",
    "\n",
    "## Define the models\n",
    "## 2* the batch size is because we duplicate everything for the contrastive part\n",
    "encoder=ContrastiveEncoderShallowME(nchan, nlatent, 2*batch_size, hidden_act_fn, latent_act_fn, dropout)\n",
    "# encoder=ContrastiveEncoderME(nchan, nlatent, hidden_act_fn, latent_act_fn, dropout)\n",
    "\n",
    "## Load in the pre-calculated model weights if they exist\n",
    "chk_file=None \n",
    "if chk_file:\n",
    "    checkpoint = torch.load(chk_file, map_location='cpu')\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "\n",
    "encoder.to(device)\n",
    "\n",
    "params_to_optimize = [\n",
    "        {'params': encoder.parameters()},\n",
    "    ]\n",
    "\n",
    "lr=1e-5\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.AdamW(params_to_optimize, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "## Scheduler options\n",
    "scheduler = None \n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=num_iterations, cycle_momentum=False)\n",
    "\n",
    "run_training(num_iterations, log_dir, encoder, temperature, train_loader, optimizer, batch_size, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now take the trained model and try to run some unsupervised learning on it...\n",
    "import numpy as np\n",
    "\n",
    "## Make a single loader to loop over for ease\n",
    "single_dataset = SingleModuleImage2D_solo_ME(inDir, transform=CenterCrop(), max_events=50000) #nevents)\n",
    "single_loader = torch.utils.data.DataLoader(single_dataset,\n",
    "                                            collate_fn=solo_ME_collate_fn,\n",
    "                                            batch_size=512,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "\n",
    "latent = []\n",
    "nhits  = []\n",
    "\n",
    "## Make this work with batches larger than 1...\n",
    "for orig_bcoords, orig_bfeats in single_loader:\n",
    "\n",
    "    orig_bcoords = orig_bcoords.to(device)\n",
    "    orig_bfeats = orig_bfeats.to(device)\n",
    "    orig_batch = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)            \n",
    "                                            \n",
    "    ## Now do the forward passes            \n",
    "    encoder.eval()\n",
    "    with torch.no_grad(): \n",
    "        encoded_batch = encoder(orig_batch)\n",
    "    \n",
    "    nhits += [i.shape[0] for i in orig_batch.decomposed_features if i.shape[0] != 0] \n",
    "    latent += [x.cpu().numpy() for x in encoded_batch.decomposed_features]\n",
    "    \n",
    "lat_vect = np.vstack(latent)\n",
    "hit_vect = np.array(nhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Make a plot of what it looks like\n",
    "plt.scatter(lat_vect[:,0], lat_vect[:,1], s=1, vmin=100, vmax=500, c=hit_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cuml.manifold import TSNE as cuML_TSNE\n",
    "import cupy as cp\n",
    "\n",
    "## Define a function for running t-SNE using the cuml version\n",
    "def run_tsne_cuml(perp=300, exag=100, input_vect=lat_vect, nhits=hit_vect):\n",
    "    print(\"Running cuML t-SNE with: perplexity =\", perp, \"early exaggeration =\", exag)\n",
    "    \n",
    "    input_vect = cp.asarray(input_vect, dtype=cp.float32)\n",
    "\n",
    "    ## I haven't played with most of cuml's t-SNE parameters\n",
    "    tsne = cuML_TSNE(n_components=2, perplexity=perp, n_iter=1000, early_exaggeration=exag, late_exaggeration=1, metric='cosine', learning_rate=100, n_neighbors=1000)\n",
    "    tsne_results = tsne.fit_transform(input_vect)\n",
    "\n",
    "    tsne_results = cp.asnumpy(tsne_results)  # Convert to NumPy for matplotlib\n",
    "\n",
    "    gr = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.2, alpha=0.8, vmin=100, vmax=500, c=nhits)\n",
    "    plt.colorbar(gr, label='N.hits')\n",
    "    plt.xlabel('t-SNE #0')\n",
    "    plt.ylabel('t-SNE #1')\n",
    "    plt.show()\n",
    "\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually run t-SNE\n",
    "perp=100\n",
    "exag=10\n",
    "tsne_results = run_tsne_cuml(perp, exag, lat_vect, hit_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.cluster import DBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "## Run DBSCAN using the cuml implementation\n",
    "def run_dbscan_gpu(eps=0.1, min_samples=20, input_vect=None):\n",
    "    if input_vect is None:\n",
    "        raise ValueError(\"input_vect must be provided.\")\n",
    "\n",
    "    print(f\"Running GPU-accelerated DBSCAN with eps={eps}, min_samples={min_samples}\")\n",
    "\n",
    "    # Normalize vectors for cosine similarity (same as CPU version)\n",
    "    input_vect = normalize(input_vect, norm='l2', axis=1)\n",
    "\n",
    "    # Move data to GPU using CuPy\n",
    "    input_vect_gpu = cp.asarray(input_vect)\n",
    "\n",
    "    # Run DBSCAN on GPU\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine', index_type='int64')\n",
    "    labels = dbscan.fit_predict(input_vect_gpu).get()  # Move result back to CPU\n",
    "\n",
    "    # Compute cluster statistics\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = np.sum(labels == -1)\n",
    "    n_points = np.bincount(labels[labels >= 0]) if n_clusters_ > 0 else []\n",
    "\n",
    "    print(f\"Estimated number of clusters: {n_clusters_}\")\n",
    "    print(f\"N. points in clusters: {n_points.tolist()}\")\n",
    "    print(f\"Estimated number of noise points: {n_noise_} (out of {len(input_vect)})\")\n",
    "\n",
    "    return labels, n_clusters_, n_noise_, n_points, dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually run an example of dbscan\n",
    "eps=0.04\n",
    "min_samples=20\n",
    "labels, n_clusters_, n_noise_, n_points, dbscan = run_dbscan_gpu(eps, min_samples, input_vect=lat_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "core_samples_mask[dbscan.core_sample_indices_.get()] = True\n",
    "\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = labels == k\n",
    "\n",
    "    xy = lat_vect[class_member_mask & core_samples_mask]\n",
    "    plt.plot(\n",
    "        xy[:, 0],\n",
    "        xy[:, 1],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=14,\n",
    "    )\n",
    "\n",
    "    xy = lat_vect[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(\n",
    "        xy[:, 0],\n",
    "        xy[:, 1],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=0.1,\n",
    "    )\n",
    "\n",
    "plt.title(f\"Estimated number of clusters: {n_clusters_}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to show examples for each cluster\n",
    "def plot_cluster_examples(dataset, labels, index, max_images=10): \n",
    "    \n",
    "    plt.figure(figsize=(12,4.5))\n",
    "\n",
    "    ## Get a mask of labels\n",
    "    indices = np.where(np.array(labels) == index)[0]\n",
    "    \n",
    "    ## Grab the first 10 images (if there are 10)\n",
    "    if len(indices) < max_images:\n",
    "        max_images = len(indices)\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(2,max_images,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "\n",
    "        orig_bcoords = orig_bcoords.to(device)\n",
    "        orig_bfeats = orig_bfeats.to(device)\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        \n",
    "        plt.imshow(inputs, origin='lower')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)            \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now pull out a bank of example images for each cluster\n",
    "\n",
    "for index in range(n_clusters_):\n",
    "    print(\"Showing examples for cluster:\", index, \"which has\", n_points[index], \"values\")\n",
    "    plot_cluster_examples(single_dataset, labels, index)\n",
    "\n",
    "print(\"Showing examples for the noise, which has\", n_noise_, \"values\")\n",
    "plot_cluster_examples(single_dataset, labels, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
