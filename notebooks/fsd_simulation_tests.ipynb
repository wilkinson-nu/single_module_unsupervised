{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bootstrap\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import MinkowskiEngine as ME\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "## Tell pytorch we have a GPU if we do\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)\n",
    "writer = SummaryWriter(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Use the common dataset loader\n",
    "from core.data.datasets import paired_2d_dataset_ME, triple_ME_collate_fn\n",
    "from core.analysis.image_utils import make_dense, make_dense_from_tensor, make_dense_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "## This function just pulls an image directly from the file, without going through a pytorch dataloder\n",
    "## You would need to have a file open: f = h5py.File(input_file, 'r')\n",
    "def show_image(i, f):\n",
    "    group = f[str(i)]\n",
    "    data = group['data'][:]\n",
    "    row = group['row'][:]\n",
    "    col = group['col'][:]\n",
    "\n",
    "    ## Use the format that ME requires                                                                                                                                                                         \n",
    "\t## Note that we can't build the sparse tensor here because ME uses some sort of global indexing                                                                                                            \n",
    "\t## And this function is replicated * num_workers                                                                                                                                                           \n",
    "    this_sparse = coo_matrix((data, (row, col)), dtype=np.float32, shape=(800, 256))    \n",
    "    this_image = this_sparse.toarray()\n",
    "\n",
    "    gr = plt.imshow(this_image, origin='lower')\n",
    "    plt.colorbar(gr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "from datasets.fsd.augmentations_2d import get_transform\n",
    "\n",
    "# Force reload so I can play with changes outside jupyter...\n",
    "import importlib\n",
    "import core.data.augmentations_2d\n",
    "importlib.reload(core.data.augmentations_2d)\n",
    "import core.data.augmentations_2d as aug\n",
    "\n",
    "## 768 is chosen to fit with the current encoder architecture\n",
    "x_max=256\n",
    "y_max=768\n",
    "\n",
    "x_orig=256\n",
    "y_orig=800\n",
    "\n",
    "x_max = x_orig\n",
    "y_max = y_orig\n",
    "\n",
    "mod_transform = transforms.Compose([\n",
    "    \t    aug.RandomBlockZeroImproved([50,100], [5,10], [0,x_orig], [0,y_orig]),\n",
    "            aug.RandomBlockZeroImproved([500,2000], [1,3], [0,x_orig], [0,y_orig]),\n",
    "            aug.RandomInPlaceHorizontalFlip(),\n",
    "            aug.RandomInPlaceVerticalFlip(),\n",
    "    \t    aug.RandomHorizontalFlip(x_max=x_orig),\n",
    "            aug.RandomVerticalFlip(y_max=y_orig),\n",
    "            aug.RandomPixelNoise2D(10),\n",
    "            aug.UnlogCharge(),\n",
    "            aug.GridJitter(),\n",
    "            aug.SplitJitterCoords(10),\n",
    "            aug.RandomShear2D(0.1, 0.1),\n",
    "            aug.RandomRotation2D(6),\n",
    "            aug.RandomStretch2D(0.1, 0.1),\n",
    "    \t    aug.RandomGridDistortion2D(100, 5, 2, 25),\n",
    "    \t    aug.RandomScaleCharge(0.05),\n",
    "        \taug.RandomJitterCharge(0.05),\n",
    "    \t    aug.BilinearSplatMod(0.3, 0.5, 0.5),\n",
    "            aug.RelogCharge(),\n",
    "       \t    aug.RandomScaleCharge(0.02),\n",
    "        \taug.RandomJitterCharge(0.02),\n",
    "            aug.SemiRandomCrop(x_max, y_max, 20),\n",
    "            ])\n",
    "\n",
    "aug_transform = mod_transform #\n",
    "# aug_transform = get_transform('fsd', \"vbigaugbilinfixnostretch\")\n",
    "\n",
    "## Load some images into a data loader\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/FSD/SIMULATIONv2\"\n",
    "data_dir = \"/pscratch/sd/c/cwilk/FSD/DATA\"\n",
    "nom_transform = transforms.Compose([\n",
    "            aug.FirstRegionCrop((800, 256), (768, 256)),\n",
    "            ])\n",
    "\n",
    "sim_dataset = paired_2d_dataset_ME(sim_dir, nom_transform=nom_transform, aug_transform=aug_transform, max_events=100000)\n",
    "data_dataset = paired_2d_dataset_ME(data_dir, nom_transform=nom_transform, aug_transform=aug_transform, max_events=100000)\n",
    "print(\"Found\", data_dataset.__len__(), \"data events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ops(A, B):\n",
    "    both = np.array([x for x in A if any((B == x).all(1))])\n",
    "    only_A = np.array([x for x in A if not any((B == x).all(1))])\n",
    "    only_B = np.array([x for x in B if not any((A == x).all(1))])\n",
    "\n",
    "    return both, only_A, only_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def profile_transforms_avg(dataset, transform_block, n_events=10):\n",
    "    times_accum = {t.__class__.__name__: [] for t in transform_block.transforms}\n",
    "\n",
    "    for idx in range(n_events):\n",
    "        _, _, _, _, coords, feats = dataset[idx]\n",
    "        for t in transform_block.transforms:\n",
    "            start = time.perf_counter()\n",
    "            coords, feats = t(coords, feats)\n",
    "            end = time.perf_counter()\n",
    "            times_accum[t.__class__.__name__].append(end - start)\n",
    "\n",
    "    times_avg = {k: np.mean(v) for k, v in times_accum.items()}\n",
    "    return times_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BilinearSplat starts at 8.911 ms averaged over 1000 events\n",
    "times = profile_transforms_avg(data_dataset, mod_transform, n_events=1000)\n",
    "times_sorted = sorted(times.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for name, t in times_sorted:\n",
    "    print(f\"{name:30s}: {t*1000:.3f} ms\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test(dataset, n=0):\n",
    "\n",
    "    aug1_bcoords, aug1_bfeats, aug2_bcoords, aug2_bfeats, orig_bcoords, orig_bfeats = dataset[n]\n",
    "\n",
    "    print(\"AUG1 #1:\", aug1_bcoords[0], aug1_bfeats[0])\n",
    "    print(\"AUG2 #1:\", aug2_bcoords[0], aug2_bfeats[0])\n",
    "    print(\"ORIG #1:\", orig_bcoords[0], orig_bfeats[0])\n",
    "\n",
    "    print(\"AUG1 SHAPE:\", aug1_bcoords.shape, aug1_bfeats.shape)\n",
    "    print(\"AUG2 SHAPE:\", aug2_bcoords.shape, aug2_bfeats.shape)    \n",
    "    print(\"ORIG SHAPE:\", orig_bcoords.shape, orig_bfeats.shape)\n",
    "\n",
    "    ## Bilinear splat should really have a threshod of ~0.5 to be close to the data distribution...\n",
    "    # print(orig_bfeats.min(), orig_bfeats.max())\n",
    "    both, only_A, only_B = set_ops(orig_bcoords, aug1_bcoords)\n",
    "    print(len(both), len(only_A), len(only_B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test(sim_dataset, 69861)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_aug_comp_plot(dataset, ids=[0], save_name=None):\n",
    "\n",
    "    cmap = cm.turbo.copy()\n",
    "    cmap.set_under(\"#F0F0F0\")\n",
    "\n",
    "    # Visualize the image\n",
    "    n_augs = 5\n",
    "    n_ids = len(ids)\n",
    "    indices = np.arange(n_augs*n_ids)\n",
    "\n",
    "    ## Set up the canvas\n",
    "    plt.figure(figsize=(n_augs*2.1, n_ids*6))\n",
    "\n",
    "    ## To keep track of the subplot\n",
    "    running_n = 0\n",
    "    \n",
    "    ## Loop over images\n",
    "    for i in ids:\n",
    "    \n",
    "        ## The dataset works with pairs, so this is just a bit hacky to get more examples\n",
    "        aug1_bcoords, aug1_bfeats, aug2_bcoords, aug2_bfeats, orig_bcoords, orig_bfeats = dataset[i]\n",
    "        aug3_bcoords, aug3_bfeats, aug4_bcoords, aug4_bfeats, _, _ = dataset[i]\n",
    "\n",
    "        ## Keep the same scale for them all\n",
    "        #orig_max = max(orig_bfeats)\n",
    "        \n",
    "        augs = [make_dense_array(orig_bcoords, orig_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug1_bcoords, aug1_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug2_bcoords, aug2_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug3_bcoords, aug3_bfeats.squeeze(), y_max, x_max),\n",
    "                make_dense_array(aug4_bcoords, aug4_bfeats.squeeze(), y_max, x_max)]\n",
    "\n",
    "        orig_max = augs[0].max()\n",
    "        orig = augs[0]\n",
    "        print(\"orig_min =\", np.min(orig[orig != 0]))\n",
    "\n",
    "        \n",
    "        ## Loop over augmentations\n",
    "        for aug in augs:\n",
    "            ax = plt.subplot(n_ids,n_augs,running_n+1)\n",
    "            # mean_val = np.mean(aug[np.isfinite(aug)]) \n",
    "            mean_val = np.mean(aug[aug != 0])\n",
    "            print(running_n, mean_val)\n",
    "            nonzero_vals = aug[aug > 0]\n",
    "            vmax = np.percentile(nonzero_vals, 80)\n",
    "            ax.imshow(aug, origin='lower', cmap=cmap, vmin=1e-6, vmax=vmax) #, vmax=orig_max)\n",
    "            ax.axis('off')\n",
    "            running_n += 1\n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_biggest_events(dataset, ret_num=1):\n",
    "\n",
    "    size_list = []\n",
    "    \n",
    "    max_event = 5000 #len(dataset)\n",
    "    for n in range(max_event):\n",
    "        if n%1000==0:\n",
    "            print(\"Processed\", n, \"/\", max_event)\n",
    "        _, _, _, _, _, orig_bfeats = dataset[n]\n",
    "        size_list.append(orig_bfeats.shape[0])\n",
    "\n",
    "    indices = np.argsort(size_list)[::-1]  # reverse for descending order\n",
    "    return indices[:ret_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = find_biggest_events(data_dataset, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "def make_aug_diff_plot(dataset, images=[0]):\n",
    "\n",
    "    ## The dataset works with pairs, so this is just a bit hacky to get more examples\n",
    "    aug1_bcoords, aug1_bfeats, aug2_bcoords, aug2_bfeats, orig_bcoords, orig_bfeats = dataset[n]\n",
    "    aug3_bcoords, aug3_bfeats, aug4_bcoords, aug4_bfeats, _, _ = dataset[n]\n",
    "\n",
    "    nom_dense  = make_dense_array(orig_bcoords, orig_bfeats.squeeze(), 800, 256)\n",
    "    aug1_dense = make_dense_array(aug1_bcoords, aug1_bfeats.squeeze(), 800, 256)\n",
    "    aug2_dense = make_dense_array(aug2_bcoords, aug2_bfeats.squeeze(), 800, 256)\n",
    "    aug3_dense = make_dense_array(aug3_bcoords, aug3_bfeats.squeeze(), 800, 256)\n",
    "    aug4_dense = make_dense_array(aug4_bcoords, aug4_bfeats.squeeze(), 800, 256)\n",
    "\n",
    "    diff1 = aug1_dense - nom_dense\n",
    "    diff2 = aug2_dense - nom_dense\n",
    "    diff3 = aug3_dense - nom_dense\n",
    "    diff4 = aug4_dense - nom_dense\n",
    "\n",
    "    augs = [nom_dense, diff1, diff2, diff3, diff4]\n",
    "    \n",
    "    vmax = max(np.max(np.abs(img)) for img in images)\n",
    "    vmin = -vmax  # symmetric around zero\n",
    "    vmin = -1\n",
    "    vmax = 1\n",
    "\n",
    "    ntotal = len(augs)\n",
    "    nimages = len(images)\n",
    "    plt.figure(figsize=(ntotal*1.8,6*nimages))\n",
    "    for i, aug in enumerate(augs, 1):\n",
    "        ax = plt.subplot(nimages, naugs, i)\n",
    "        im = ax.imshow(aug, origin='lower', cmap='seismic', vmin=vmin, vmax=vmax)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dump a few events!\n",
    "## Interesting numbers: 3, 28, 50, 75, 77, 95, 179, 237, 239, 272, 303, 347, 69861, 73664, 16498\n",
    "test_list = [16498, 179, 69861]\n",
    "make_aug_comp_plot(data_dataset, test_list, save_name=\"example_augmentations.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
