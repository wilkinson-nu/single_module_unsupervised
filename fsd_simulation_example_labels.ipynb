{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "## Tell pytorch we have a GPU if we do\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Use the common dataset loader\n",
    "from ME_dataset_libs import SingleModuleImage2D_solo_ME, solo_ME_collate_fn\n",
    "from ME_dataset_libs import make_dense, make_dense_from_tensor, make_dense_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "## This function just pulls an image directly from the file, without going through a pytorch dataloder\n",
    "## You would need to have a file open: f = h5py.File(input_file, 'r')\n",
    "def show_image(i, f):\n",
    "    group = f[str(i)]\n",
    "    data = group['data'][:]\n",
    "    row = group['row'][:]\n",
    "    col = group['col'][:]\n",
    "\n",
    "    ## Use the format that ME requires                                                                                                                                                                         \n",
    "\t## Note that we can't build the sparse tensor here because ME uses some sort of global indexing                                                                                                            \n",
    "\t## And this function is replicated * num_workers                                                                                                                                                           \n",
    "    this_sparse = coo_matrix((data, (row, col)), dtype=np.float32, shape=(800, 256))    \n",
    "    this_image = this_sparse.toarray()\n",
    "\n",
    "    gr = plt.imshow(this_image, origin='lower')\n",
    "    plt.colorbar(gr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup the dataloader\n",
    "import time\n",
    "from ME_dataset_libs import FirstRegionCrop, DoNothing\n",
    "start = time.process_time() \n",
    "\n",
    "## Modify the nominal transform\n",
    "#nom_transform = transforms.Compose([\n",
    "#            FirstRegionCrop((800, 256), (768, 256)),\n",
    "#            ConstantCharge(),\n",
    "#            ])\n",
    "nom_transform=DoNothing()\n",
    "\n",
    "data_dir = \"/pscratch/sd/c/cwilk/FSD/DATA\"\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/FSD/SIMULATIONv2\"\n",
    "max_data_events=200000\n",
    "max_sim_events=200000\n",
    "single_sim_dataset = SingleModuleImage2D_solo_ME(sim_dir, transform=nom_transform, max_events=max_sim_events)\n",
    "single_data_dataset = SingleModuleImage2D_solo_ME(data_dir, transform=nom_transform, max_events=max_data_events)\n",
    "\n",
    "print(\"Time taken to load\", single_data_dataset.__len__(),\"data and\", single_sim_dataset.__len__(), \"images:\", time.process_time() - start)\n",
    "\n",
    "data_loader   = torch.utils.data.DataLoader(single_data_dataset,\n",
    "                                            collate_fn=solo_ME_collate_fn,\n",
    "                                            batch_size=1024,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "\n",
    "sim_loader    = torch.utils.data.DataLoader(single_sim_dataset,\n",
    "                                            collate_fn=solo_ME_collate_fn,\n",
    "                                            batch_size=1024,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_image_loop(loader):\n",
    "    nhits = []\n",
    "    maxQ = []\n",
    "    sumQ = []\n",
    "    labels = []\n",
    "    y_range = []\n",
    "    x_range = []    \n",
    "    \n",
    "    ## Loop over the images (discard any extra info returned by loader)\n",
    "    for batch_coords, batch_feats, batch_labels, *_ in loader:\n",
    "\n",
    "        batch_size = len(batch_labels)\n",
    "        batch_coords = batch_coords.to(device)\n",
    "        batch_feats = batch_feats.to(device)\n",
    "        orig_batch = ME.SparseTensor(batch_feats, batch_coords, device=device)   \n",
    "\n",
    "        y_range += [torch.max(i[:,0]).item()-torch.min(i[:,0]).item() for i in orig_batch.decomposed_coordinates]\n",
    "        x_range += [torch.max(i[:,1]).item()-torch.min(i[:,1]).item() for i in orig_batch.decomposed_coordinates]\n",
    "        nhits += [i.shape[0] for i in orig_batch.decomposed_features]\n",
    "        sumQ += [i.sum().item() for i in orig_batch.decomposed_features]\n",
    "        maxQ += [i.max().item() for i in orig_batch.decomposed_features]\n",
    "        labels += [i for i in batch_labels]\n",
    "\n",
    "    ## Return a dictionary to make my life easier\n",
    "    return {\n",
    "        \"nhits\": np.array(nhits),\n",
    "        \"sumQ\": np.array(sumQ),\n",
    "        \"maxQ\": np.array(maxQ),\n",
    "        \"labels\": np.array(labels),\n",
    "        \"yrange\": np.array(y_range),\n",
    "        \"xrange\":np.array(x_range),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the processed vectors of interest from the datasets                                                                                                                                                     \n",
    "data_raw = raw_image_loop(data_loader)\n",
    "sim_raw = raw_image_loop(sim_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Visualise data\n",
    "from matplotlib import cm\n",
    "from ME_dataset_libs import Label\n",
    "def make_label_comp_plot(sim_dataset, sim_raw, min_hits=20, save_name=None):\n",
    "\n",
    "    cmap = cm.turbo.copy()\n",
    "    cmap.set_under(\"#F0F0F0\")\n",
    "    \n",
    "    ## How many labels are there? (skip data)\n",
    "    label_values = [m.value for m in Label]\n",
    "    label_names  = [m.name for m in Label]\n",
    "\n",
    "    ## OLD\n",
    "    # new_names = [r\"EM\", r\"Neutron\", r\"Proton\", r\"External $\\mu$\", r\"Multi-$\\mu$\", r\"$\\mu$-capture\", r\"$\\mu$-decay\", \"Clean MIP\", \"Messy MIP\"]\n",
    "    # labels_to_show = [1, 2, 3, 6, 5, 7, 8, 10, 11]\n",
    "\n",
    "    ## NEW\n",
    "    new_names = [\"Clean MIP\", \"Messy MIP\", r\"$\\mu$-capture\", r\"$\\mu$-decay\", r\"Multi-$\\mu$\", r\"EM\", r\"Neutron\", r\"Proton\", r\"External $\\mu$\"]\n",
    "    labels_to_show = [10, 11, 7, 8, 5, 1, 2, 3, 6]\n",
    "    \n",
    "    nlabels = len(labels_to_show)\n",
    "    \n",
    "    ## Set up the figure so there's one subfigure per label\n",
    "    plt.figure(figsize=(nlabels*1.8,6))\n",
    "\n",
    "    ## Loop over labels\n",
    "    for l in range(nlabels):\n",
    "        lval = labels_to_show[l]\n",
    "\n",
    "        ## Selected id\n",
    "        idx = 0\n",
    "\n",
    "        ## Calculate fractions\n",
    "        this_frac = np.sum(sim_raw['labels'] == label_values[lval])/float(len(sim_dataset))*100\n",
    "        \n",
    "        ## Pick a reasonable choice at random for throughgoing and stopping\n",
    "        if \"THROUGH\" in label_names[lval] or \"STOPPING\" in label_names[lval]:\n",
    "            lindices = np.where((sim_raw['labels'] == label_values[lval]) & (sim_raw['nhits'] > min_hits))[0]\n",
    "            idx = lindices[0]\n",
    "        else:\n",
    "            # Step 1: get indices matching the label condition\n",
    "            label_mask = (sim_raw['labels'] == label_values[lval])\n",
    "            filtered_indices = np.where(label_mask)[0]\n",
    "\n",
    "            # Step 2: find the index of the max nhits among those indices\n",
    "            max_idx_within_filtered = np.argmax(sim_raw['nhits'][filtered_indices])\n",
    "\n",
    "            # Step 3: map back to original array index\n",
    "            idx = filtered_indices[max_idx_within_filtered]\n",
    "        \n",
    "        coords, feats, *_ = sim_dataset[idx]\n",
    "        ax = plt.subplot(1,nlabels,l+1)\n",
    "        inputs = make_dense_array(coords, feats.squeeze(), 800, 256)\n",
    "        nonzero_vals = inputs[inputs > 0]\n",
    "        vmax = np.percentile(nonzero_vals, 80)\n",
    "        gr = plt.imshow(inputs, origin='lower', cmap=cmap, vmin=1e-6, vmax=vmax)\n",
    "        ax.axis('off')\n",
    "        ax.set_xlabel(label_names[lval], fontsize=12)\n",
    "        ax.text(0.5, -0.01, f\"{new_names[l]}\\n({this_frac:.2f}%)\", ha='center', va='top', transform=ax.transAxes, fontsize=12)\n",
    "    \n",
    "    if save_name: plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_label_comp_plot(single_sim_dataset, sim_raw, 600, 'example_labels.jpg')\n",
    "# print(len(single_sim_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
