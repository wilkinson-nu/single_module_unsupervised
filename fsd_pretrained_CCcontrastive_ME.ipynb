{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import MinkowskiEngine as ME\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.v2.functional as F\n",
    "from torch import nn\n",
    "\n",
    "## Jupyter magic\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "import numpy as np\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Includes from my libraries for this project                                                                                                                                           \n",
    "from ME_NN_libs import CCEncoderFSD, ProjectionHead, ClusteringHead\n",
    "from ME_dataset_libs import CenterCrop, MaxRegionCrop, ConstantCharge, RandomCrop, RandomPixelNoise2D\n",
    "from ME_dataset_libs import SingleModuleImage2D_solo_ME, solo_ME_collate_fn, solo_ME_collate_fn_with_meta\n",
    "from ME_dataset_libs import make_dense, make_dense_from_tensor, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the pretrained model, set a few other parameters\n",
    "nchan=64\n",
    "nlatent=128\n",
    "nclusters=20\n",
    "temp=0.5\n",
    "enc_act_fn=ME.MinkowskiSiLU\n",
    "hidden_act_fn=nn.SiLU\n",
    "latent_act_fn=nn.Tanh\n",
    "dropout=0\n",
    "lr=\"5E-6\"\n",
    "batch_size=1024\n",
    "aug_type=\"unitcharge\"\n",
    "\n",
    "## Define the model    \n",
    "encoder=CCEncoderFSD(nchan, enc_act_fn, dropout)\n",
    "proj_head = ProjectionHead(nchan, nlatent, hidden_act_fn, latent_act_fn)\n",
    "clust_head = ClusteringHead(nchan, nclusters, hidden_act_fn)\n",
    "\n",
    "## Load in the pre-calculated model weights\n",
    "file_dir = \"/pscratch/sd/c/cwilk\"\n",
    "chk_file = file_dir+\"/state_lat\"+str(nlatent)+\"_clust\"+str(nclusters)+\"_nchan\"+str(nchan)+\"_\"+lr+\"_\"+str(batch_size)+\"_PROJ0.5CLUST0.5_onecycle50_unitcharge_2M_FSDCC.pth\"\n",
    "\n",
    "print(chk_file)\n",
    "\n",
    "checkpoint = torch.load(chk_file, map_location=device)\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "proj_head.load_state_dict(checkpoint['proj_head_state_dict'])\n",
    "clust_head.load_state_dict(checkpoint['clust_head_state_dict'])\n",
    "\n",
    "encoder.eval()\n",
    "proj_head.eval()\n",
    "clust_head.eval()\n",
    "\n",
    "encoder.to(device)\n",
    "proj_head.to(device)\n",
    "clust_head.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup the dataloader\n",
    "from torch.utils.data import ConcatDataset\n",
    "import time\n",
    "start = time.process_time() \n",
    "\n",
    "## Modify the nominal transform\n",
    "nom_transform = transforms.Compose([\n",
    "            MaxRegionCrop((256, 800), (256,512)),\n",
    "            ConstantCharge(),\n",
    "            ])\n",
    "\n",
    "data_dir = \"/pscratch/sd/c/cwilk/FSD/DATA\"\n",
    "sim_dir = \"/pscratch/sd/c/cwilk/FSD/SIMULATION\"\n",
    "single_sim_dataset = SingleModuleImage2D_solo_ME(sim_dir, transform=nom_transform, max_events=250000, return_metadata=True)\n",
    "single_data_dataset = SingleModuleImage2D_solo_ME(data_dir, transform=nom_transform, max_events=250000, return_metadata=True)\n",
    "single_mixed_dataset = ConcatDataset([single_data_dataset, single_sim_dataset])\n",
    "\n",
    "print(\"Time taken to load\", single_data_dataset.__len__(),\"data and\", single_sim_dataset.__len__(), \"images:\", time.process_time() - start)\n",
    "\n",
    "## Randomly chosen batching\n",
    "single_loader = torch.utils.data.DataLoader(single_mixed_dataset,\n",
    "                                            collate_fn=solo_ME_collate_fn_with_meta,\n",
    "                                            batch_size=1024,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Encode the images we'll work with here (can take a while)\n",
    "latent = []\n",
    "cluster = []\n",
    "nhits  = []\n",
    "filenames = []\n",
    "event_ids = []\n",
    "labels = []\n",
    "\n",
    "encoder.eval()\n",
    "proj_head.eval()\n",
    "clust_head.eval()\n",
    "\n",
    "## Note that this uses the loader including metadata so it's possible to trace back to the input files\n",
    "for orig_bcoords, orig_bfeats, batch_labels, batch_filenames, batch_eventids in single_loader:\n",
    "\n",
    "    batch_size = len(batch_filenames)\n",
    "    orig_bcoords = orig_bcoords.to(device)\n",
    "    orig_bfeats = orig_bfeats.to(device)\n",
    "    orig_batch = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)            \n",
    "                                            \n",
    "    ## Now do the forward passes            \n",
    "    with torch.no_grad(): \n",
    "        encoded_batch = encoder(orig_batch, batch_size)\n",
    "        clust_batch = clust_head(encoded_batch.F)\n",
    "        proj_batch = proj_head(encoded_batch.F)\n",
    "\n",
    "    nhits += [i.shape[0] for i in orig_batch.decomposed_features] \n",
    "    cluster += [x[np.newaxis, :] for x in clust_batch.detach().cpu().numpy()]\n",
    "    latent += [x[np.newaxis, :] for x in proj_batch.detach().cpu().numpy()]\n",
    "    filenames += [i for i in batch_filenames]\n",
    "    event_ids += [i for i in batch_eventids]\n",
    "    labels += [i for i in batch_labels]\n",
    "\n",
    "## The image-wise latent space\n",
    "latent_vect = np.vstack(latent)\n",
    "\n",
    "## The pre-clustered space\n",
    "cluster_vect = np.vstack(cluster)\n",
    "\n",
    "## The index of the maximum value in cluster space\n",
    "clust_index = np.argmax(cluster_vect, axis=1)\n",
    "\n",
    "## The maximum value in cluster space\n",
    "clust_max = np.max(cluster_vect, axis=1)\n",
    "\n",
    "## The number of hits in the input image\n",
    "hit_vect = np.array(nhits)\n",
    "\n",
    "## The label of the input image (-1 for data)\n",
    "label_vect = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(clust_max, bins=50, edgecolor='black')\n",
    "plt.xlabel('Maximum value (per row)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of maximum values across 20 features')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(clust_index, bins=np.arange(nclusters+1)-0.5, edgecolor='black')\n",
    "plt.xlabel('Index of max value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of max indices')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.manifold import TSNE as cuML_TSNE\n",
    "import cupy as cp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib\n",
    "\n",
    "## Define a function for running t-SNE using the cuml version\n",
    "def run_tsne_cuml(perp=30, exag=100, lr=lr, input_vect=latent_vect, zvect=clust_index):\n",
    "    print(\"Running cuML t-SNE with: perplexity =\", perp, \"early exaggeration =\", exag)\n",
    "    \n",
    "    input_vect = normalize(input_vect, norm='l2')\n",
    "    input_vect = cp.asarray(input_vect, dtype=cp.float32)\n",
    "\n",
    "    print(\"Input shape:\", input_vect.shape)\n",
    "    print(\"Input range:\", input_vect.min(), input_vect.max())\n",
    "    \n",
    "    ## I haven't played with most of cuml's t-SNE parameters\n",
    "    tsne = cuML_TSNE(n_components=2, perplexity=perp, n_iter=5000, \\\n",
    "                     early_exaggeration=exag, learning_rate=lr, \\\n",
    "                     learning_rate_method=None, \\\n",
    "                     metric='cosine', method='barnes_hut', verbose=True)\n",
    "    tsne_results = tsne.fit_transform(input_vect)\n",
    "\n",
    "    tsne_results = cp.asnumpy(tsne_results)  # Convert to NumPy for matplotlib\n",
    "    tsne_results = StandardScaler().fit_transform(tsne_results)\n",
    "\n",
    "    unique_labels = np.unique(zvect)\n",
    "    n_clusters = len(unique_labels)\n",
    "\n",
    "    # Use a qualitative colormap with enough colors\n",
    "    cmap = matplotlib.colormaps['tab20']\n",
    "    norm = mcolors.BoundaryNorm(boundaries=np.arange(n_clusters + 1), ncolors=n_clusters)\n",
    "    \n",
    "    gr = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.005, alpha=0.9, c=zvect, cmap=cmap, norm=norm)\n",
    "    plt.colorbar(gr, label='Cluster ID')\n",
    "    plt.xlabel('t-SNE #0')\n",
    "    plt.ylabel('t-SNE #1')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"t-SNE output min/max:\", tsne_results.min(), tsne_results.max())\n",
    "    print(\"t-SNE output std per dim:\", tsne_results.std(axis=0))\n",
    "    return tsne_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actually run tsne (not always that useful)\n",
    "perp=30\n",
    "exag=6\n",
    "lr=2000.0\n",
    "tsne_results = run_tsne_cuml(perp, exag, lr, latent_vect, clust_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to make column normalized histograms\n",
    "from matplotlib.colors import LogNorm\n",
    "def make_2D_histogram(x_vect, y_vect, norm='column', label_enum=Label):\n",
    "    # Determine range of unique integer values\n",
    "    x_min, x_max = x_vect.min(), x_vect.max()\n",
    "    y_min, y_max = y_vect.min(), y_vect.max()\n",
    "\n",
    "    # Define bin edges so each integer gets its own bin\n",
    "    x_bins = np.arange(x_min, x_max + 2)  # +2 to include the last integer\n",
    "    y_bins = np.arange(y_min, y_max + 2)\n",
    "\n",
    "    # Compute the 2D histogram\n",
    "    H, xedges, yedges = np.histogram2d(x_vect, y_vect, bins=[x_bins, y_bins])\n",
    "    H = H.T\n",
    "    \n",
    "    # Column normalization: divide each column by its sum\n",
    "    # Note: H shape is (len(x_bins)-1, len(y_bins)-1)\n",
    "    column_sums = H.sum(axis=0, keepdims=True)\n",
    "    row_sums = H.sum(axis=1, keepdims=True)\n",
    "\n",
    "    \n",
    "    if norm=='column': \n",
    "        H_normalized = np.divide(H, column_sums, where=column_sums != 0)\n",
    "    elif norm=='row':\n",
    "        H_normalized = np.divide(H, row_sums, where=row_sums != 0)\n",
    "    else:\n",
    "        print(\"Unknown norm option:, norm\")\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    mesh = plt.pcolormesh(x_bins, y_bins, H_normalized, cmap='viridis', shading='auto')\n",
    "    plt.colorbar(mesh, label='Normalized Frequency (per '+norm+')')\n",
    "    plt.ylabel(\"Cluster ID\")\n",
    "\n",
    "    if label_enum is not None:\n",
    "        x_ticks = np.arange(x_min, x_max + 1)\n",
    "        x_labels = [label_enum.name_from_index(i) for i in x_ticks]\n",
    "        plt.xticks(ticks=x_ticks + 1, labels=x_labels, rotation=45, ha='right')\n",
    "    plt.yticks(ticks=y_bins[:-1])\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_2D_histogram(label_vect, clust_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_2D_histogram(label_vect, clust_index, 'row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to show examples for each cluster\n",
    "def plot_cluster_examples(dataset, cluster_ids, index, max_images=8): \n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ## Get a mask of cluster_ids\n",
    "    indices = np.where(np.array(cluster_ids) == index)[0]\n",
    "    \n",
    "    ## Grab the first 10 images (if there are 10)\n",
    "    if len(indices) < max_images:\n",
    "        max_images = len(indices)\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(2,max_images,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, _, _, _ = dataset[indices[i]]\n",
    "\n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "\n",
    "        orig_bcoords = orig_bcoords.to(device)\n",
    "        orig_bfeats = orig_bfeats.to(device)\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 512, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        \n",
    "        plt.imshow(inputs, origin='lower')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)            \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now pull out a bank of example images for each cluster\n",
    "for index in range(nclusters):\n",
    "    print(\"Showing examples for cluster:\", index, \"which has\", np.count_nonzero(clust_index==index), \"values\")\n",
    "    plot_cluster_examples(single_mixed_dataset, clust_index, index, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to show a big block of examples for each cluster\n",
    "## index == None will just give an unclustered set\n",
    "def plot_cluster_bigblock(dataset, cluster_ids, index, max_x=10, max_y=10, save_name=None): \n",
    "    \n",
    "    plt.figure(figsize=(max_y*2, max_x*1.8*2))\n",
    "    ## Get a mask of cluster_ids\n",
    "    indices = np.arange(max_x*max_y) \n",
    "    if index != None: indices = np.where(np.array(cluster_ids) == index)[0]\n",
    "    max_images = min(len(indices), max_x*max_y)\n",
    "    print(len(indices))\n",
    "    \n",
    "    ## Plot\n",
    "    for i in range(max_images):\n",
    "        ax = plt.subplot(max_x,max_y,i+1)\n",
    "        \n",
    "        numpy_coords, numpy_feats, _, _, _ = dataset[indices[i]]\n",
    "    \n",
    "        # Create batched coordinates for the SparseTensor input\n",
    "        orig_bcoords  = ME.utils.batched_coordinates([numpy_coords])\n",
    "        orig_bfeats  = torch.from_numpy(np.concatenate([numpy_feats], 0)).float()\n",
    "\n",
    "        orig_bcoords = orig_bcoords.to(device)\n",
    "        orig_bfeats = orig_bfeats.to(device)\n",
    "        orig = ME.SparseTensor(orig_bfeats, orig_bcoords, device=device)\n",
    "            \n",
    "        inputs  = make_dense_from_tensor(orig, 0, 512, 256)\n",
    "        inputs  = inputs .cpu().squeeze().numpy()\n",
    "        \n",
    "        plt.imshow(inputs, origin='lower')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)    \n",
    "    plt.tight_layout()\n",
    "    if save_name: plt.savefig(save_name, dpi=150, bbox_inches='tight')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dump out a large block of images for one cluster\n",
    "plot_cluster_bigblock(single_mixed_dataset, clust_index, 17, 10, 10) #, 'cluster_plots/v9_michel_like.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tools_ME",
   "language": "python",
   "name": "ml_tools_me"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
